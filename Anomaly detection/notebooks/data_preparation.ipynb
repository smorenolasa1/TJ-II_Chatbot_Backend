{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Activate the virtual environment: \n",
    "source /Users/sofiamorenolasa/Desktop/TFG/.venv/bin/activate\n",
    "2. Switch to the virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   N_DESCARGA       fecha   hora comentarioDesc comentarioExp configuracion  \\\n",
      "0         112  19971217.0  19:05            NaN           NaN           NaN   \n",
      "1         113  19971217.0  19:09            NaN           NaN           NaN   \n",
      "2         114  19971217.0  19:55            NaN           NaN           NaN   \n",
      "3         115  19971218.0  11:08            NaN           NaN           NaN   \n",
      "4         116  19971218.0  11:28            NaN           NaN           NaN   \n",
      "\n",
      "   potencia_radiada  energia_diamagnetica  retraso_densidad_girotron  zeff  \\\n",
      "0               NaN                   NaN                        NaN   NaN   \n",
      "1               NaN                   NaN                        NaN   NaN   \n",
      "2               NaN                   NaN                        NaN   NaN   \n",
      "3               NaN                   NaN                        NaN   NaN   \n",
      "4               NaN                   NaN                        NaN   NaN   \n",
      "\n",
      "   ...  IAccel_nominal_NBI2  tini_NBI2  longitud_pulso_nominal_NBI2  \\\n",
      "0  ...                  NaN        NaN                          NaN   \n",
      "1  ...                  NaN        NaN                          NaN   \n",
      "2  ...                  NaN        NaN                          NaN   \n",
      "3  ...                  NaN        NaN                          NaN   \n",
      "4  ...                  NaN        NaN                          NaN   \n",
      "\n",
      "   potencia_nominal_NBI2  potencia_through_port_NBI2  VAccel_real_NBI2  \\\n",
      "0                    NaN                         NaN               NaN   \n",
      "1                    NaN                         NaN               NaN   \n",
      "2                    NaN                         NaN               NaN   \n",
      "3                    NaN                         NaN               NaN   \n",
      "4                    NaN                         NaN               NaN   \n",
      "\n",
      "   IAccel_real_NBI2  longitud_pulso_real_NBI2  updated_NBI2  \\\n",
      "0               NaN                       NaN           NaN   \n",
      "1               NaN                       NaN           NaN   \n",
      "2               NaN                       NaN           NaN   \n",
      "3               NaN                       NaN           NaN   \n",
      "4               NaN                       NaN           NaN   \n",
      "\n",
      "   factor_transm_NBI2  \n",
      "0                 NaN  \n",
      "1                 NaN  \n",
      "2                 NaN  \n",
      "3                 NaN  \n",
      "4                 NaN  \n",
      "\n",
      "[5 rows x 155 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b6/pb_stfjn0pb7pybgwlqjk5700000gn/T/ipykernel_87239/2676448733.py:6: DtypeWarning: Columns (52,55,96,132,133,144,145) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path, delimiter=\";\", encoding=\"latin1\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"../data/PARAMETROS_TJ2.csv\"\n",
    "\n",
    "# Use latin1 encoding\n",
    "data = pd.read_csv(file_path, delimiter=\";\", encoding=\"latin1\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we sort the PARAMETROS_TJ2.csv file by the N_DESCARGA field and save the sorted data to a new file named PARAMETROS_TJ2_ORDENADOS.csv. This ensures the rows are ordered starting from the smallest N_DESCARGA value to the largest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b6/pb_stfjn0pb7pybgwlqjk5700000gn/T/ipykernel_87239/1307042932.py:8: DtypeWarning: Columns (52,55,96,132,133,144,145) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(input_file_path, delimiter=\";\", encoding=\"latin1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted data saved to ../data/PARAMETROS_TJ2_ORDENADOS.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "input_file_path = \"../data/PARAMETROS_TJ2.csv\"  # Replace with the correct path\n",
    "output_file_path = \"../data/PARAMETROS_TJ2_ORDENADOS.csv\"\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv(input_file_path, delimiter=\";\", encoding=\"latin1\")\n",
    "\n",
    "# Convert N_DESCARGA to numeric, coercing errors to NaN\n",
    "data['N_DESCARGA'] = pd.to_numeric(data['N_DESCARGA'], errors='coerce')\n",
    "\n",
    "# Drop rows where N_DESCARGA is NaN (invalid values)\n",
    "data = data.dropna(subset=['N_DESCARGA'])\n",
    "\n",
    "# Ensure N_DESCARGA is an integer\n",
    "data['N_DESCARGA'] = data['N_DESCARGA'].astype(int)\n",
    "\n",
    "# Sort by N_DESCARGA in ascending order\n",
    "data_sorted = data.sort_values(by='N_DESCARGA')\n",
    "\n",
    "# Save the sorted dataset to a new CSV file\n",
    "data_sorted.to_csv(output_file_path, index=False, sep=\";\", encoding=\"latin1\")\n",
    "\n",
    "print(f\"Sorted data saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will convert this .csv file to a .txt to help with training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODIFY THE TEXT BELOW TO INCLUDE ONLY THE IMPORTANT FIELDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b6/pb_stfjn0pb7pybgwlqjk5700000gn/T/ipykernel_87239/1245340582.py:16: DtypeWarning: Columns (52,54,55,96,105,108,110,122,125,129,132,133,137,138,143,144,145,150,151,154) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(csv_path, delimiter=';', encoding='latin1', on_bad_lines='skip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ../data/txt_output/PARAMETROS_TJ2_ORDENADOS.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def process_csv_to_txt(csv_path, txt_path):\n",
    "    \"\"\"\n",
    "    Processes a CSV file with semicolon delimiters, extracts and cleans relevant data,\n",
    "    and saves it as a .txt file.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the input CSV file.\n",
    "        txt_path (str): Path to save the output .txt file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file with semicolon as the delimiter\n",
    "        data = pd.read_csv(csv_path, delimiter=';', encoding='latin1', on_bad_lines='skip')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {csv_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Initialize the text content\n",
    "    text = ''\n",
    "\n",
    "    # Iterate over the rows of the CSV\n",
    "    for index, row in data.iterrows():\n",
    "        # Extract the necessary fields (customize this based on your analysis needs)\n",
    "        descarga = row.get('N_DESCARGA', 'N/A')\n",
    "        fecha = row.get('fecha', 'N/A')\n",
    "        comentario = row.get('comentarioDesc', 'N/A')\n",
    "        configuracion = row.get('configuracion', 'N/A')\n",
    "        energia_diamagnetica = row.get('energia_diamagnetica', 'N/A')\n",
    "\n",
    "        # Format the extracted data into a readable string\n",
    "        text += (\n",
    "            f\"Descarga: {descarga}\\n\"\n",
    "            f\"Fecha: {fecha}\\n\"\n",
    "            f\"Comentario: {comentario}\\n\"\n",
    "            f\"Configuración: {configuracion}\\n\"\n",
    "            f\"Energía Diamagnética: {energia_diamagnetica}\\n\"\n",
    "            f\"{'-'*40}\\n\"  # Separator for readability\n",
    "        )\n",
    "\n",
    "    # Save the processed text to the output file\n",
    "    try:\n",
    "        with open(txt_path, 'w', encoding='utf-8') as txt_file:\n",
    "            txt_file.write(text)\n",
    "        print(f\"Processed data saved to {txt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to {txt_path}: {e}\")\n",
    "\n",
    "\n",
    "# Input and output paths\n",
    "csv_path = \"../data/PARAMETROS_TJ2_ORDENADOS.csv\"\n",
    "txt_folder = \"../data/txt_output/\"\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(txt_folder, exist_ok=True)\n",
    "\n",
    "# Generate the output .txt file name\n",
    "txt_path = os.path.join(txt_folder, \"PARAMETROS_TJ2_ORDENADOS.txt\")\n",
    "\n",
    "# Process the CSV and save it as a .txt file\n",
    "process_csv_to_txt(csv_path, txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b6/pb_stfjn0pb7pybgwlqjk5700000gn/T/ipykernel_47698/3740190966.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'N/A' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data.fillna(\"N/A\", inplace=True)\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Question: What is the fecha for N_DESCARGA 4?\n",
      "Answer: No matching data found in the table.\n",
      "\n",
      "Question: What is the hora for N_DESCARGA 6458?\n",
      "Answer: No matching data found in the table.\n",
      "\n",
      "Question: What is the comentarioDesc for N_DESCARGA 12?\n",
      "Answer: No matching data found in the table.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"../data/PARAMETROS_TJ2_ORDENADOS.csv\"  # Replace with your file path\n",
    "data = pd.read_csv(file_path, delimiter=\";\", encoding=\"latin1\", low_memory=False)\n",
    "\n",
    "# Handle missing values and convert all columns to strings\n",
    "data.fillna(\"N/A\", inplace=True)\n",
    "data[\"N_DESCARGA\"] = data[\"N_DESCARGA\"].astype(int)  # Ensure \"N_DESCARGA\" is treated as integers\n",
    "data = data.astype(str)  # Convert the entire DataFrame to strings for TAPAS compatibility\n",
    "\n",
    "# Reduce table size to relevant columns if needed\n",
    "columns_to_keep = [\"N_DESCARGA\", \"fecha\", \"hora\", \"comentarioDesc\"]\n",
    "data = data[columns_to_keep].sort_values(by=\"N_DESCARGA\").reset_index(drop=True)\n",
    "\n",
    "# Load the TAPAS pipeline with the base model\n",
    "pipe = pipeline(\"table-question-answering\", model=\"google/tapas-base-finetuned-wtq\", device=-1)  # Force CPU usage\n",
    "\n",
    "\n",
    "# Binary search algorithm to find the row with the target N_DESCARGA\n",
    "def binary_search_discharge(data, target):\n",
    "    low, high = 0, len(data) - 1\n",
    "    \n",
    "    while low <= high:\n",
    "        mid = (low + high) // 2\n",
    "        mid_value = int(data.iloc[mid][\"N_DESCARGA\"])  # Ensure mid_value is treated as an integer\n",
    "        \n",
    "        if mid_value == target:\n",
    "            return data.iloc[[mid]]  # Return the row as a DataFrame\n",
    "        elif mid_value < target:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            high = mid - 1\n",
    "    \n",
    "    return pd.DataFrame()  # Return empty DataFrame if not found\n",
    "\n",
    "\n",
    "# Define questions\n",
    "questions = [\n",
    "    \"What is the fecha for N_DESCARGA 4?\",\n",
    "    \"What is the hora for N_DESCARGA 6458?\",\n",
    "    \"What is the comentarioDesc for N_DESCARGA 12?\"\n",
    "]\n",
    "\n",
    "# Process each question\n",
    "print(\"\\nResults:\")\n",
    "for question in questions:\n",
    "    try:\n",
    "        # Extract the N_DESCARGA value from the question\n",
    "        query_value = int(question.split()[-1].strip(\"?\"))\n",
    "\n",
    "        # Use binary search to find the relevant row\n",
    "        filtered_table = binary_search_discharge(data, query_value)\n",
    "\n",
    "        # Check if the filtered table is empty\n",
    "        if filtered_table.empty:\n",
    "            print(f\"Question: {question}\")\n",
    "            print(\"Answer: No matching data found in the table.\\n\")\n",
    "            continue\n",
    "\n",
    "        # Run the pipeline with the filtered table\n",
    "        answer = pipe(table=filtered_table, query=question)\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Answer: {answer['answer']}\\n\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing question: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during TAPAS processing for question '{question}': {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b6/pb_stfjn0pb7pybgwlqjk5700000gn/T/ipykernel_47698/3740190966.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'N/A' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data.fillna(\"N/A\", inplace=True)\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Question: What is the fecha for N_DESCARGA 4?\n",
      "Answer: No matching data found in the table.\n",
      "\n",
      "Question: What is the hora for N_DESCARGA 6458?\n",
      "Answer: No matching data found in the table.\n",
      "\n",
      "Question: What is the comentarioDesc for N_DESCARGA 12?\n",
      "Answer: No matching data found in the table.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"../data/PARAMETROS_TJ2_ORDENADOS.csv\"  # Replace with your file path\n",
    "data = pd.read_csv(file_path, delimiter=\";\", encoding=\"latin1\", low_memory=False)\n",
    "\n",
    "# Handle missing values and convert all columns to strings\n",
    "data.fillna(\"N/A\", inplace=True)\n",
    "data[\"N_DESCARGA\"] = data[\"N_DESCARGA\"].astype(int)  # Ensure \"N_DESCARGA\" is treated as integers\n",
    "data = data.astype(str)  # Convert the entire DataFrame to strings for TAPAS compatibility\n",
    "\n",
    "# Reduce table size to relevant columns if needed\n",
    "columns_to_keep = [\"N_DESCARGA\", \"fecha\", \"hora\", \"comentarioDesc\"]\n",
    "data = data[columns_to_keep].sort_values(by=\"N_DESCARGA\").reset_index(drop=True)\n",
    "\n",
    "# Load the TAPAS pipeline with the base model\n",
    "pipe = pipeline(\"table-question-answering\", model=\"google/tapas-base-finetuned-wtq\", device=-1)  # Force CPU usage\n",
    "\n",
    "\n",
    "# Binary search algorithm to find the row with the target N_DESCARGA\n",
    "def binary_search_discharge(data, target):\n",
    "    low, high = 0, len(data) - 1\n",
    "    \n",
    "    while low <= high:\n",
    "        mid = (low + high) // 2\n",
    "        mid_value = int(data.iloc[mid][\"N_DESCARGA\"])  # Ensure mid_value is treated as an integer\n",
    "        \n",
    "        if mid_value == target:\n",
    "            return data.iloc[[mid]]  # Return the row as a DataFrame\n",
    "        elif mid_value < target:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            high = mid - 1\n",
    "    \n",
    "    return pd.DataFrame()  # Return empty DataFrame if not found\n",
    "\n",
    "\n",
    "# Define questions\n",
    "questions = [\n",
    "    \"What is the fecha for N_DESCARGA 4?\",\n",
    "    \"What is the hora for N_DESCARGA 6458?\",\n",
    "    \"What is the comentarioDesc for N_DESCARGA 12?\"\n",
    "]\n",
    "\n",
    "# Process each question\n",
    "print(\"\\nResults:\")\n",
    "for question in questions:\n",
    "    try:\n",
    "        # Extract the N_DESCARGA value from the question\n",
    "        query_value = int(question.split()[-1].strip(\"?\"))\n",
    "\n",
    "        # Use binary search to find the relevant row\n",
    "        filtered_table = binary_search_discharge(data, query_value)\n",
    "\n",
    "        # Check if the filtered table is empty\n",
    "        if filtered_table.empty:\n",
    "            print(f\"Question: {question}\")\n",
    "            print(\"Answer: No matching data found in the table.\\n\")\n",
    "            continue\n",
    "\n",
    "        # Run the pipeline with the filtered table\n",
    "        answer = pipe(table=filtered_table, query=question)\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Answer: {answer['answer']}\\n\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing question: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during TAPAS processing for question '{question}': {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que borrar los datos repetidos, hay muchos donde la hora y la fecha son iguales, aunque el numero de descarga sea diferente, así que habría que dejar solo uno. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
